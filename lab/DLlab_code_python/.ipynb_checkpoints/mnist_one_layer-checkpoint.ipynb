{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "2ZfaQIUpDZvO"
   },
   "source": [
    "# Classification of hand-written digits\n",
    "\n",
    "Start by loading the tensorflow package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ME0y6IHDZvV",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-677c8b11fe06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "from six.moves import urllib\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7hW6rEcLDZvk"
   },
   "source": [
    "The following functions are needed to load the data. Just execute the cell below, do not bother about all the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "MsIgyGIYDZvo",
    "outputId": "9bfe83a4-241a-4d5b-9eec-84871b76bf9e"
   },
   "outputs": [],
   "source": [
    "SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
    "WORK_DIRECTORY = 'data'\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CHANNELS = 1\n",
    "NUM_LABELS = 10\n",
    "def maybe_download(filename):\n",
    "  \"\"\"Download the data from Yann's website, unless it's already here.\"\"\"\n",
    "  if not tf.gfile.Exists(WORK_DIRECTORY):\n",
    "    tf.gfile.MakeDirs(WORK_DIRECTORY)\n",
    "  filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "  if not tf.gfile.Exists(filepath):\n",
    "    filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
    "    with tf.gfile.GFile(filepath) as f:\n",
    "      size = f.size()\n",
    "    print('Successfully downloaded', filename, size, 'bytes.')\n",
    "  return filepath\n",
    "\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "  \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "  Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "  \"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(16)\n",
    "    buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "    data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "  \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(8)\n",
    "    buf = bytestream.read(1 * num_images)    \n",
    "    labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)    \n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    for value in labels:\n",
    "        letter = [0 for _ in range(0,NUM_LABELS)]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)    \n",
    "    labels_onehot_encoded  = np.array(onehot_encoded)\n",
    "    return labels_onehot_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download, extract and load the mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data.\n",
    "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Extract it into numpy arrays.\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "test_labels = extract_labels(test_labels_filename, 10000)\n",
    "\n",
    "# Dataset size\n",
    "train_size = train_labels.shape[0]\n",
    "test_size = test_labels.shape[0]\n",
    "\n",
    "# Normalize the data\n",
    "train_data = train_data/255.0\n",
    "test_data = test_data/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JetLsyAjDZv3"
   },
   "source": [
    "### The model\n",
    "\n",
    "Define placeholders for the data. The input data Xim are $28\\times 28$ pixels grayscale images. The first dimension None will be the number of data points, determined when launching the graph. This placeholder is flattend into a matrix with $28\\times 28=784$ columns, where each colum represents one pixel. The placeholder for the output data Y is a one hot encoding representing the 10 different classes. One hot encoding for the class \"0\" is [1 0 0 0 0 0 0 0 0 0], for class \"1\" is [0 1 0 0 0 0 0 0 0 0] and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dY4YhlKADZv8"
   },
   "outputs": [],
   "source": [
    "# The placeholder for the input\n",
    "Xim = tf.placeholder(dtype = tf.float32, shape = [None, 28, 28, 1])\n",
    "\n",
    "# Number of data points (in the present batch)\n",
    "batchsize = tf.shape(Xim)[[0]]\n",
    "\n",
    "# Flatten the data into a matrix with  28 x 28 = 784 columns\n",
    "X = tf.reshape(tensor = Xim, shape = [batchsize,784 ])\n",
    "\n",
    "# The placeholder of the output. \n",
    "Y = tf.placeholder(dtype = tf.float32, shape = [None, 10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9EIqz-8xDZwD"
   },
   "source": [
    "Define the weights of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17o1UGjoDZwF"
   },
   "outputs": [],
   "source": [
    "# The weights of dimension W[784,10]\n",
    "W = tf.Variable(initial_value = tf.zeros([784, 10]))\n",
    "\n",
    "# The offset vector of dimension b[10]\n",
    "b = tf.Variable(initial_value = tf.zeros(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZCkPZjz-DZwM"
   },
   "source": [
    "Define the actual network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wXZv2X7DZwP"
   },
   "outputs": [],
   "source": [
    "# The network model\n",
    "P = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NYMZmV_GDZwa"
   },
   "source": [
    "### The training \n",
    "Define the loss function and the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOpD7LKcDZwe"
   },
   "outputs": [],
   "source": [
    "# The loss function: Compute the cross-entropy\n",
    "cross_entropy = -tf.reduce_mean(tf.reduce_sum(Y * tf.log(P), reduction_indices=1))\n",
    "\n",
    "# Define the training\n",
    "gamma = 0.5 # The learning rate\n",
    "train_step = tf.train.GradientDescentOptimizer(gamma).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSpeO0byDZwx"
   },
   "source": [
    "Accuracy of the trained model. 0 is worst and 1 is the best.\n",
    "These lines are for evaluating the performance. Don't bother to much about them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1B5xLOnDZw0"
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(P, 1) # In each row of Q, determine the index of the column with highest probability\n",
    "true = tf.argmax(Y, 1) \n",
    "correct_prediction = tf.equal(true, prediction) # Compare with true labels. TRUE if correct, FALSE if not.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "rJ4jX9FDDZxB"
   },
   "source": [
    "Launch the graph and train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "id": "pid_KnP5DZxD",
    "outputId": "837ddb2a-fa37-4ac7-dd67-e0e6043732cf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create session and initialize  variables\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Initialize the test and training error resutls\n",
    "test_accuracy = []\n",
    "test_cross_entropy = []\n",
    "test_iter = []\n",
    "train_accuracy = []\n",
    "train_cross_entropy = []\n",
    "train_iter = []\n",
    "\n",
    "BATCH_SIZE = 100 # Batch size\n",
    "NUM_ITERATIONS = 2000 # Total number of iterations\n",
    "iter_in_one_epoch = np.floor_divide(train_size,BATCH_SIZE) # Number of iterations in each epoch\n",
    "# The main training loop\n",
    "for t in range(0, NUM_ITERATIONS+1):\n",
    "    \n",
    "    # The iteration number in the present epoch\n",
    "    j = (t%iter_in_one_epoch)\n",
    "    \n",
    "    # If a new epoch, reshuffle the data indices\n",
    "    if j == 0:\n",
    "        train_ind = np.random.choice(train_size,size=train_size, replace=False)        \n",
    "        \n",
    "    # Compute the indices of the batch\n",
    "    offset = j*BATCH_SIZE\n",
    "    batch_ind = train_ind[offset:(offset+BATCH_SIZE)]\n",
    "    \n",
    "    # Extract a batch with BATCH_SIZE images and labels\n",
    "    batch_xs = train_data[batch_ind, ...]\n",
    "    batch_ys = train_labels[batch_ind,]        \n",
    "    \n",
    "    # Do one gradient setp\n",
    "    sess.run(train_step,feed_dict = {Xim: batch_xs, Y: batch_ys})\n",
    "\n",
    "    # Evaluate the performance on training data\n",
    "    # These lines are for evaluating the performance. Don't bother too much about them!\n",
    "\n",
    "    if (t%10 == 0):        \n",
    "        # Evaluate on test data\n",
    "        train_tmp = sess.run([accuracy,cross_entropy], feed_dict = {Xim: batch_xs, Y: batch_ys})\n",
    "        train_accuracy.append(train_tmp[0])\n",
    "        train_cross_entropy.append(train_tmp[1])\n",
    "        train_iter.append(t)\n",
    "\n",
    "    # Evaluate the performance on training data at every 100th itertation\n",
    "    # These lines are for evaluating the performance. Don't bother too much about them!\n",
    "\n",
    "    if (t%100==0):\n",
    "        # Evaluate on test data\n",
    "        test_tmp = sess.run([accuracy,cross_entropy], feed_dict = {Xim: test_data, Y: test_labels})\n",
    "        test_accuracy.append(test_tmp[0])\n",
    "        test_cross_entropy.append(test_tmp[1])\n",
    "        test_iter.append(t)\n",
    "\n",
    "        # Also print iteration number and prediction accuracy\n",
    "        print(\"Step %d: train acc. %.2f  train cross-entropy %.2f test acc. %.3f  test cross-entropy %.3f\" % (t,train_tmp[0],train_tmp[1],test_tmp[0],test_tmp[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wY9MEi2xDZxM"
   },
   "source": [
    "### The evaluation\n",
    "\n",
    "The remaining code produces the plots needed to evaluate the training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "colab_type": "code",
    "id": "L_MSLJvoD28u",
    "outputId": "2be25bd3-0568-4590-faa2-39de35251d61"
   },
   "outputs": [],
   "source": [
    "# Do the plot of cross entropy\n",
    "plt.plot(train_iter, train_cross_entropy,'b-', label='Training data (mini-batch)')\n",
    "plt.plot(test_iter, test_cross_entropy,'r-', label='Testing data')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cross-entropy')\n",
    "plt.ylim([0,min(test_cross_entropy)*3])\n",
    "plt.title('Cross-entropy')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Do the plot of accuracy\n",
    "plt.plot(train_iter, train_accuracy,'b-', label='Training data (mini-batch)')\n",
    "plt.plot(test_iter, test_accuracy,'r-', label='Testing data')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Prediction accuracy')\n",
    "plt.ylim([max(1-(1-test_accuracy[-1])*2,0),1])\n",
    "plt.title('Prediction accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on all test data\n",
    "tmp = sess.run([prediction,P], feed_dict = {Xim: test_data})\n",
    "test_pred = tmp[0]\n",
    "test_P = tmp[1]\n",
    "test_true = sess.run(true, feed_dict = {Y: test_labels})\n",
    "\n",
    "# Close the session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "id": "caWJ8PwaDZxO",
    "outputId": "1d3e738d-e278-425a-ddb7-bcda6a4565f4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract 100 random test images\n",
    "batch_test_ind = np.random.choice(test_size,100)\n",
    "batch_test_ind_wrong_first = batch_test_ind[np.argsort(test_true[batch_test_ind]==test_pred[batch_test_ind])]\n",
    "\n",
    "# Do the plot of the images\n",
    "num_rows = 10\n",
    "num_cols = 10\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(num_cols, num_rows))\n",
    "\n",
    "for i, i_im in enumerate(batch_test_ind_wrong_first, 1):\n",
    "    plt.subplot(num_rows, num_cols, i)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(test_data[i_im,:,:,0], cmap=plt.cm.binary)    \n",
    "    if test_pred[i_im]==test_true[i_im]:\n",
    "          plt.text(0, 25, test_pred[i_im], fontsize=25, color='blue')\n",
    "    else:\n",
    "          plt.text(0, 25, test_pred[i_im], fontsize=25, color='red')    \n",
    "                  \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "mnist_one_layer.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
